{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekczNcQxUpzT"
      },
      "source": [
        "# Your Uni : Fill Here. (Also change Uni in the title of your notebook)\n",
        "# Your Full name : Fill Here\n",
        "# Link to your Public Github repository with Final report  : Fill here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXxGTgJz152A"
      },
      "source": [
        "# World Happiness Classification Competition\n",
        "Goals :\n",
        "- Understand how the models function\n",
        "- Understand what the parameters control\n",
        "- Learn from the model experimentation process\n",
        "- Make a good looking notebook report\n",
        "- Upload as a personal project on Github\n",
        "\n",
        "**Overall Steps:**\n",
        "1. Get data in and set up X_train / X_test / y_train\n",
        "2. Preprocess data using Sklearn Column Transformer/ Write and Save Preprocessor function\n",
        "3. Fit model on preprocessed data and save preprocessor function and model\n",
        "4. Generate predictions from X_test data and submit predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSrVJwp3E9H"
      },
      "source": [
        "## 0. Get data in and set up X_train, X_test, y_train objects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions:**\n",
        "Upload the world_happiness_competition_data.zip and newcountryvars.csv files on Colab by pressing the Folder icon on left tab (Shows \"Files\" on hovering), and then clicking the left-most file upload button (Shows \"Upload to Session Storage\" Alt text on hovering)"
      ],
      "metadata": {
        "id": "iemh36mSklGo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-YsXXXcUQ9G"
      },
      "outputs": [],
      "source": [
        "# Get training data from course folder and unzip\n",
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(\"world_happiness_competition_data.zip\", 'r') as zObject:\n",
        "\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT0qFCZFNzHq"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "import pandas as pd\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = ## Load test features to predict on\n",
        "y_train = ## Load y train (true labels)\n",
        "y_test = ## Load y test (true labels)\n",
        "y_train_labels = y_train.idxmax(axis=1) ## Examine what this does and write in next cell\n",
        "y_test_labels = ## Complete in a similar manner as above\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write in the next cell what the y_train_labels = y_train.idxmax(axis=1) line does. What is the difference between y_train_labels and y_train?"
      ],
      "metadata": {
        "id": "KvTXc7QOl5s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer:"
      ],
      "metadata": {
        "id": "DsFZm1z0l0EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbevDQ9_8-pt"
      },
      "source": [
        "##  Add new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFBU6SBm896W"
      },
      "outputs": [],
      "source": [
        "# Truncated and cleaned up region data to merge\n",
        "countrydata=pd.read_csv(\"newcountryvars.csv\")\n",
        "\n",
        "countrydata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iMJhqME9Lmq"
      },
      "outputs": [],
      "source": [
        "# Merge in new data to X_train and X_test by taking \"Country or region\" from first table and \"country_name\" from 2nd table.\n",
        "\n",
        "X_train = ## Complete code\n",
        "X_test = ## Complete code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAcRWzym-4iT"
      },
      "outputs": [],
      "source": [
        "X_train.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "3MV_a5QaydpZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM5kFt5zC4yn"
      },
      "outputs": [],
      "source": [
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe what you see above?"
      ],
      "metadata": {
        "id": "eBngMQdmykLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer:"
      ],
      "metadata": {
        "id": "Phkm6BKCyjuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find out the number and percentage of missing values in the table per column"
      ],
      "metadata": {
        "id": "OmlG3-8Tys3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here:"
      ],
      "metadata": {
        "id": "ejFHu-84y2Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the frequency distribution / histogram of some of the numerical features that you think are important"
      ],
      "metadata": {
        "id": "c7Q3_DMwy4sX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your plotting code here:"
      ],
      "metadata": {
        "id": "neosQxQRzKfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the categorical variables and their distribution"
      ],
      "metadata": {
        "id": "F0MxV_o9zNCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your plotting code here:"
      ],
      "metadata": {
        "id": "17wHJ4hYzRkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore relationships between variables (bivariate, etc), correlation tables, and how they associate with the target variable."
      ],
      "metadata": {
        "id": "Oi3lA3QElvZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your plotting code(s) here:"
      ],
      "metadata": {
        "id": "91OgPpv8mQ3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write what you observed and your General comments on what should be done:"
      ],
      "metadata": {
        "id": "878CQ8e9zTf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your comments here"
      ],
      "metadata": {
        "id": "V_C7nCaYzZ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzPoXPj3V7u"
      },
      "source": [
        "##2.   Preprocess data using Sklearn Column Transformer/ Write and Save Preprocessor function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16QV9Y9TC3B3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Create the preprocessing pipelines for both numeric and categorical data.\n",
        "\n",
        "numeric_features = ## Drop all the non-numerical features from X_train\n",
        "numeric_features=numeric_features.columns.tolist()\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)), ## Is this good enough?\n",
        "    ('scaler', StandardScaler())]) # You will need to describe why this is being done in the next cell\n",
        "\n",
        "categorical_features = ['region', 'sub-region']\n",
        "\n",
        "#Replacing missing values with Modal value and then one hot encoding.\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer',  ## Fill here )),\n",
        "    ('onehot', OneHotEncoder(handle_unknown= ## Fill here  ))])\n",
        "\n",
        "# final preprocessor object set up with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features),('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "#Fit your preprocessor object\n",
        "preprocess=preprocessor.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe step-by-step what we are doing above, and why? You are free to change how values are imputed. What change did you make if any, and why?"
      ],
      "metadata": {
        "id": "a-_wL1ZfnnRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer :"
      ],
      "metadata": {
        "id": "7_k1H1XvnlEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_PaNOG0SUIk"
      },
      "outputs": [],
      "source": [
        "# Write function to transform data with preprocessor\n",
        "\n",
        "def preprocessor(data):\n",
        "    data.drop(['Country or region', 'name'], axis=1)\n",
        "    preprocessed_data=preprocess.transform(data)\n",
        "    return preprocessed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the differences between the \"preprocessor\" object, the \"preprocess\" object, the \"preprocessor\" function,  and the \"preprocessed_data\" that is returned finally?"
      ],
      "metadata": {
        "id": "ihlVBhHQnxdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your Answer :"
      ],
      "metadata": {
        "id": "KgszpguCoBkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1IPy9xvSWBp"
      },
      "outputs": [],
      "source": [
        "# check shape of X data after preprocessing it using our new function\n",
        "preprocessor(X_train).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X52kECL43b-O"
      },
      "source": [
        "##3. Fit model on preprocessed data and save preprocessor function and model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCbBf8j9ClYl"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = ## Define a Random Forest Model here, fit it, and score it\n",
        "\n",
        "# Your cell should have a score between 0-1 as output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHWkAzvX3m8O"
      },
      "source": [
        "## 4. Generate predictions from X_test data and compare it with true labels in Y_test.csv file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ql4wksyEUnP"
      },
      "outputs": [],
      "source": [
        "#-- Generate predicted values (Model 1)\n",
        "prediction_labels = model.predict(preprocessor(X_test))\n",
        "\n",
        "## Write code to show model performance by comparing prediction_labels with true labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Repeat submission process to improve place on leaderboard\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "SLg12oeqeP12"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model_2 = ## Make a new model with changed parameters to improve the score"
      ],
      "metadata": {
        "id": "PYG5FywVeP17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " What changes did you make, what do the parameters you changed control, and why does it improve performance?"
      ],
      "metadata": {
        "id": "bYMEPL2UrWn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer :"
      ],
      "metadata": {
        "id": "SaGdMOIcrmX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nszPPrfwPlUk"
      },
      "outputs": [],
      "source": [
        "#Evaluate Model 2:\n",
        "\n",
        "#-- Generate predicted y values (Model 2)\n",
        "prediction_labels = # Predict\n",
        "\n",
        "## Write code to show model performance by comparing prediction_labels with true labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think it is worth making more changes to the parameters? Should we keep trying random values and see what works better? What is an alternative to doing this manually?"
      ],
      "metadata": {
        "id": "yhzJ7NGOtehX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer:"
      ],
      "metadata": {
        "id": "7Sx3ivg1td_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Go4SF37Ex_Z"
      },
      "outputs": [],
      "source": [
        "# Submit a third model using GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "param_grid = # Use np.arange to create a sequence of numbers for each parameter's space you think should be searched\n",
        "\n",
        "gridmodel = # Read GridSearchCV docs and create an object with RandomForestClassifier as the model\n",
        "\n",
        "#use model methods to fit score and predict model:\n",
        "\n",
        "\n",
        "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
        "print(\"best mean cross-validation score: {:.3f}\".format(gridmodel.best_score_))\n",
        "print(\"best parameters: {}\".format(gridmodel.best_params_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMidHABfHVN7"
      },
      "outputs": [],
      "source": [
        "#Submit Model 3:\n",
        "\n",
        "#-- Generate predicted values\n",
        "\n",
        "\n",
        "## Write code to show model performance by comparing prediction_labels with true labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tukB40NshcaB"
      },
      "outputs": [],
      "source": [
        "# Here are several classic ML architectures you can consider choosing from to experiment with next:\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "model = ## Read documentations of imported models and fit them.\n",
        "\n",
        "#-- Generate predicted values\n",
        "prediction_labels = model.predict(preprocessor(X_test))\n",
        "\n",
        "## Write code to show model performance by comparing prediction_labels with true labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe what were the parameters you defined in GradientBoostingClassifier, and/or BaggingClassifier, and/or KNNs, and/or SVC? What worked and why?"
      ],
      "metadata": {
        "id": "zeZ16W4GuUW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer:"
      ],
      "metadata": {
        "id": "SJkWFWGPuGk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Basic Deep Learning"
      ],
      "metadata": {
        "id": "2e-V2vtMmrrp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me2pkDUsuEBH"
      },
      "outputs": [],
      "source": [
        "# Now experiment with deep learning models:\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "feature_count=#count features in input data\n",
        "\n",
        "keras_model = ## Define a Neural Network Model with 5 layers 128->64->64->32->(?)\n",
        "\n",
        "\n",
        "#Use Softmax activation in last layer. How many neurons should there be in the last layer?\n",
        "\n",
        "\n",
        "\n",
        "# Compile model\n",
        "keras_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the NN to the Training set\n",
        "keras_model.fit(preprocessor(X_train), y_train, ## Note that keras models require a one-hot-encoded y_train object\n",
        "               batch_size = 20,\n",
        "               epochs = 300, validation_split=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which activations did you use in the middle layers? Why was softmax used in the last layer?"
      ],
      "metadata": {
        "id": "3ioCyMzn004c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer:"
      ],
      "metadata": {
        "id": "gIDjsg1C07Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Was it a good idea to train for 300 epochs? Should you train a bit more? Why or why not?"
      ],
      "metadata": {
        "id": "vJjQq2Uzu3IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer:"
      ],
      "metadata": {
        "id": "UfyiD8SKvF-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is loss='categorical_crossentropy' and optimizer='sgd'? Would you want to change something? Why / Why not?"
      ],
      "metadata": {
        "id": "mHwaKILrvID4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your answer:"
      ],
      "metadata": {
        "id": "QmpDqteVv8wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you try getting the model's training history out and plotting the curves?"
      ],
      "metadata": {
        "id": "fT8-NUAaopVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Your code to plot training and validation curves in a single plot (Make changes in the model cell to be able to do this)"
      ],
      "metadata": {
        "id": "FtmlgVsAoyU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_uMRKnGu-wC"
      },
      "outputs": [],
      "source": [
        "#-- Generate predicted y values\n",
        "\n",
        "#Note: Keras predict returns the predicted column index location for classification models\n",
        "prediction_column_index= # Predict\n",
        "\n",
        "# extract correct prediction labels\n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "## Write code to show model performance by comparing prediction_labels with true labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You are encouraged to try more experimentation and any other models by adding more code cells to this notebook:\n",
        "\n",
        "## You can also try to import any new dataset pertaining to countries, merge it, and see if it helps the predictions.\n",
        "## If it does not, try to explain why it wasn't helpful by exploring variable relationships."
      ],
      "metadata": {
        "id": "NnsyzAcHwOiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning models are often considered 'black boxes' due to their complexity. Explore methods such as SHAP (SHapley Additive exPlanations) to explain your model's predictions. After applying one of these methods, do you feel it provides a clear and sufficient explanation of how your model makes decisions? How easy or difficult is it to justify your model's predictions using these techniques?"
      ],
      "metadata": {
        "collapsed": false,
        "id": "u79b6VFqeP19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Your Code and Answer:"
      ],
      "metadata": {
        "id": "LeJ9bKQNeP19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Submission of final report and clean code to github\n",
        "\n",
        "[This is a final project you display on your GitHub to the World]\n",
        "\n",
        "**Instructions**\n",
        "- Make a new notebook, visualize any plots you found relevant\n",
        "- Reproduce the code you used for the best models and display results\n",
        "- Write what insights you found useful and what behaviours were observed\n",
        "- Make it in a style of a clean, succint report (within the .ipynb)\n",
        "- Upload this final report notebook to a new repository in your personal github account\n",
        "- Remember to paste the link of your final repo at the top of this notebook where asked"
      ],
      "metadata": {
        "id": "LAy-p3odm0zv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3KjLkz5plvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}